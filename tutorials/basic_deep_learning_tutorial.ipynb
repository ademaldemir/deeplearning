{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic-deep-learning-tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDQKHHj2Efmh",
        "colab_type": "text"
      },
      "source": [
        "https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDavGiUqWepr",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6TKBc6NEdYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first neural network with keras tutorial\n",
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW9jT_c3Ehi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the dataset\n",
        "dataset = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz6XFdwAFpsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = loadtxt('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', delimiter=',')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jftDnjrF29J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into input (X) and output (y) variables\n",
        "X = df[:, 0:8]\n",
        "y = df[:, 8]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR79SAhWVIvd",
        "colab_type": "text"
      },
      "source": [
        "# Define Keras Model\n",
        "We can piece it all together by adding each layer:\n",
        "\n",
        "- The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
        "- The first hidden layer has 12 neurons or nodes and uses the relu activation function.\n",
        "- The second hidden layer has 8 nodes and uses the relu activation function.\n",
        "- The output layer has one node and uses the sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nuqwnu0GU_Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim = 8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXecrhzAWOmc",
        "colab_type": "text"
      },
      "source": [
        "#Â Compile Keras Model\n",
        "\n",
        "When compiling, we must specify some additional properties required when training the network. **Remember training a network means finding the best set of weights to map inputs to outputs in our dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpQ6Fw2VVbDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j906x1kWXsJ_",
        "colab_type": "text"
      },
      "source": [
        "#  Fit Keras Model\n",
        "\n",
        "We have defined our model and compiled it ready for efficient computation.\n",
        "\n",
        "Now it is time to execute the model on some data.\n",
        "\n",
        "We can train or fit our model on our loaded data by calling the fit() function on the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeKdK-GWXs8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61992ebf-9c6f-4074-be48-23c2476ca704"
      },
      "source": [
        " # fit the keras model on the dataset\n",
        " model.fit(X,y, epochs=150, batch_size=10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 0s 901us/step - loss: 12.3177 - accuracy: 0.5312\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 819us/step - loss: 2.3880 - accuracy: 0.5625\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 937us/step - loss: 1.3335 - accuracy: 0.6172\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 873us/step - loss: 1.1687 - accuracy: 0.6276\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 939us/step - loss: 1.2516 - accuracy: 0.6263\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 946us/step - loss: 0.9347 - accuracy: 0.6628\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 957us/step - loss: 0.9119 - accuracy: 0.6602\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 954us/step - loss: 0.8266 - accuracy: 0.6341\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.8387 - accuracy: 0.6393\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 864us/step - loss: 0.7968 - accuracy: 0.6562\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 864us/step - loss: 0.8729 - accuracy: 0.6406\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 898us/step - loss: 0.7883 - accuracy: 0.6484\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 859us/step - loss: 0.8614 - accuracy: 0.6497\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 873us/step - loss: 0.6826 - accuracy: 0.6836\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 899us/step - loss: 0.7386 - accuracy: 0.6732\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.6707 - accuracy: 0.6901\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 869us/step - loss: 0.7349 - accuracy: 0.6680\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 837us/step - loss: 0.6871 - accuracy: 0.6745\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.6714 - accuracy: 0.6875\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 885us/step - loss: 0.7011 - accuracy: 0.6758\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 927us/step - loss: 0.6746 - accuracy: 0.6927\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 874us/step - loss: 0.7252 - accuracy: 0.6471\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 881us/step - loss: 0.7044 - accuracy: 0.6758\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 894us/step - loss: 0.6650 - accuracy: 0.6784\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 838us/step - loss: 0.7704 - accuracy: 0.6471\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 867us/step - loss: 0.7868 - accuracy: 0.6576\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 918us/step - loss: 0.6852 - accuracy: 0.6615\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 916us/step - loss: 0.7170 - accuracy: 0.6823\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 858us/step - loss: 0.7781 - accuracy: 0.6589\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.6927\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.7161\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 983us/step - loss: 0.5870 - accuracy: 0.7057\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.7057\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.6992\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 985us/step - loss: 0.6496 - accuracy: 0.6732\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.6875\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 905us/step - loss: 0.8390 - accuracy: 0.6419\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6791 - accuracy: 0.6927\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 861us/step - loss: 0.5855 - accuracy: 0.7214\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 915us/step - loss: 0.6076 - accuracy: 0.7135\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.6406 - accuracy: 0.6745\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 993us/step - loss: 0.6233 - accuracy: 0.6966\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 974us/step - loss: 0.6875 - accuracy: 0.6654\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 998us/step - loss: 0.6203 - accuracy: 0.7096\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 990us/step - loss: 0.6850 - accuracy: 0.6719\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6966\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.6693\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 956us/step - loss: 0.6383 - accuracy: 0.6927\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6979\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 863us/step - loss: 0.5847 - accuracy: 0.7214\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 870us/step - loss: 0.6245 - accuracy: 0.6758\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 894us/step - loss: 0.6639 - accuracy: 0.6693\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 839us/step - loss: 0.6669 - accuracy: 0.6576\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 890us/step - loss: 0.6217 - accuracy: 0.7005\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 862us/step - loss: 0.6031 - accuracy: 0.7096\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 853us/step - loss: 0.5997 - accuracy: 0.7122\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 939us/step - loss: 0.6325 - accuracy: 0.6927\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 865us/step - loss: 0.5844 - accuracy: 0.7240\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 864us/step - loss: 0.5477 - accuracy: 0.7227\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 925us/step - loss: 0.6748 - accuracy: 0.6823\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 899us/step - loss: 0.5634 - accuracy: 0.7227\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 900us/step - loss: 0.5755 - accuracy: 0.7292\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.5455 - accuracy: 0.7318\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 820us/step - loss: 0.6809 - accuracy: 0.7044\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 876us/step - loss: 0.6184 - accuracy: 0.6836\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 841us/step - loss: 0.8883 - accuracy: 0.6510\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.6098 - accuracy: 0.7148\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 869us/step - loss: 0.5929 - accuracy: 0.7292\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 940us/step - loss: 0.6460 - accuracy: 0.6875\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 865us/step - loss: 0.5746 - accuracy: 0.7096\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 873us/step - loss: 0.6232 - accuracy: 0.7109\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 856us/step - loss: 0.6294 - accuracy: 0.7109\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 855us/step - loss: 0.5637 - accuracy: 0.7122\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 941us/step - loss: 0.5520 - accuracy: 0.7161\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 840us/step - loss: 0.5870 - accuracy: 0.7161\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 848us/step - loss: 0.5683 - accuracy: 0.7305\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 861us/step - loss: 0.5775 - accuracy: 0.7305\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 859us/step - loss: 0.5711 - accuracy: 0.7227\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 855us/step - loss: 0.5244 - accuracy: 0.7487\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 928us/step - loss: 0.5649 - accuracy: 0.7214\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 853us/step - loss: 0.5798 - accuracy: 0.7109\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 897us/step - loss: 0.5823 - accuracy: 0.7253\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6456 - accuracy: 0.7057\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7253\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 974us/step - loss: 0.6364 - accuracy: 0.6992\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7240\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 980us/step - loss: 0.5514 - accuracy: 0.7474\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.7044\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 980us/step - loss: 0.5711 - accuracy: 0.7201\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 907us/step - loss: 0.6230 - accuracy: 0.7057\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.6180 - accuracy: 0.7214\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 902us/step - loss: 0.5795 - accuracy: 0.7122\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 855us/step - loss: 0.5888 - accuracy: 0.7292\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 875us/step - loss: 0.5827 - accuracy: 0.7174\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.5573 - accuracy: 0.7227\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 847us/step - loss: 0.5369 - accuracy: 0.7214\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 860us/step - loss: 0.5884 - accuracy: 0.7057\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 889us/step - loss: 0.5962 - accuracy: 0.7005\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 852us/step - loss: 0.5698 - accuracy: 0.7227\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 840us/step - loss: 0.5344 - accuracy: 0.7578\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 934us/step - loss: 0.5909 - accuracy: 0.7031\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 883us/step - loss: 0.5726 - accuracy: 0.7266\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 851us/step - loss: 0.5404 - accuracy: 0.7188\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 905us/step - loss: 0.6064 - accuracy: 0.7383\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.5585 - accuracy: 0.7578\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 832us/step - loss: 0.5542 - accuracy: 0.7409\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 896us/step - loss: 0.6627 - accuracy: 0.6979\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 891us/step - loss: 0.5440 - accuracy: 0.7331\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 856us/step - loss: 0.5391 - accuracy: 0.7357\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.5683 - accuracy: 0.7188\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7617\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 880us/step - loss: 0.5270 - accuracy: 0.7461\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 857us/step - loss: 0.5568 - accuracy: 0.7253\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 918us/step - loss: 0.5301 - accuracy: 0.7604\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 931us/step - loss: 0.5220 - accuracy: 0.7513\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 843us/step - loss: 0.5616 - accuracy: 0.7331\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 914us/step - loss: 0.5859 - accuracy: 0.7174\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 868us/step - loss: 0.6768 - accuracy: 0.6836\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 852us/step - loss: 0.6525 - accuracy: 0.7057\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 856us/step - loss: 0.5639 - accuracy: 0.7370\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 970us/step - loss: 0.5391 - accuracy: 0.7292\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 979us/step - loss: 0.5265 - accuracy: 0.7318\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 973us/step - loss: 0.5648 - accuracy: 0.7318\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6979\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 995us/step - loss: 0.5867 - accuracy: 0.7109\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7070\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5515 - accuracy: 0.7500\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7513\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.7370\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7396\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.5248 - accuracy: 0.7539\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.5664 - accuracy: 0.7331\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 853us/step - loss: 0.5271 - accuracy: 0.7578\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7435\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 999us/step - loss: 0.5732 - accuracy: 0.7227\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7539\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7279\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.7279\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 964us/step - loss: 0.5241 - accuracy: 0.7552\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6143 - accuracy: 0.7344\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5745 - accuracy: 0.7396\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 951us/step - loss: 0.6173 - accuracy: 0.7083\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 888us/step - loss: 0.5413 - accuracy: 0.7487\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 832us/step - loss: 0.5351 - accuracy: 0.7409\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 844us/step - loss: 0.5125 - accuracy: 0.7565\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 867us/step - loss: 0.5237 - accuracy: 0.7539\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7669\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 880us/step - loss: 0.5274 - accuracy: 0.7487\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 870us/step - loss: 0.5310 - accuracy: 0.7474\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.6637 - accuracy: 0.7070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f494d4fc080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1F4OTnJY_dM",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Keras Model\n",
        "You can evaluate your model on your training dataset using the evaluate() function on your model and pass it the same input and output used to train the model.\n",
        "\n",
        "The **evaluate()** function will return a list with two values. The first will be the loss of the model on the dataset and the second will be the accuracy of the model on the dataset. We are only interested in reporting the accuracy, so we will ignore the loss value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeNtUNy_YXVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "539deab6-ebd9-4fa3-94c8-264a63d9831f"
      },
      "source": [
        "# evaluate the keras model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print('Loss: {:.2f}'.format(loss) +', Accuracy: {:.2f}'.format(accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 926us/step - loss: 0.5251 - accuracy: 0.7487\n",
            "Loss: 0.53, Accuracy: 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tsFGDv7oEeM",
        "colab_type": "text"
      },
      "source": [
        "# Tie It All Together\n",
        "\n",
        "Letâs tie it all together into a complete code example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlEASA1rZhPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4671b04-98af-4379-966d-74a8aec89c6d"
      },
      "source": [
        "#first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#load the dataset\n",
        "dataset = loadtxt('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv', delimiter=',')\n",
        "#split into input (X) and output (y) variables\n",
        "X = dataset[:, 0:8]\n",
        "y = dataset[:, 8]\n",
        "#define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10)\n",
        "#evaluate the keras model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print('Loss: {:.2f}'.format(loss) +', Accuracy: {:.2f}'.format(accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 0s 983us/step - loss: 5.9571 - accuracy: 0.4427\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 896us/step - loss: 1.0430 - accuracy: 0.6276\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 828us/step - loss: 0.8583 - accuracy: 0.6289\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 877us/step - loss: 0.7753 - accuracy: 0.6484\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 942us/step - loss: 0.7236 - accuracy: 0.6445\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 860us/step - loss: 0.6919 - accuracy: 0.6654\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 844us/step - loss: 0.6725 - accuracy: 0.6576\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 812us/step - loss: 0.6626 - accuracy: 0.6510\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 899us/step - loss: 0.6530 - accuracy: 0.6589\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 825us/step - loss: 0.6399 - accuracy: 0.6602\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 827us/step - loss: 0.6310 - accuracy: 0.6641\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 804us/step - loss: 0.6215 - accuracy: 0.6914\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 874us/step - loss: 0.6224 - accuracy: 0.6771\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 834us/step - loss: 0.6195 - accuracy: 0.6849\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 831us/step - loss: 0.6047 - accuracy: 0.6901\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.6015 - accuracy: 0.6953\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 996us/step - loss: 0.6049 - accuracy: 0.6901\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 873us/step - loss: 0.5926 - accuracy: 0.7070\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 834us/step - loss: 0.5818 - accuracy: 0.7044\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 886us/step - loss: 0.5783 - accuracy: 0.7070\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 830us/step - loss: 0.5771 - accuracy: 0.7044\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 860us/step - loss: 0.5741 - accuracy: 0.7083\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 918us/step - loss: 0.5660 - accuracy: 0.7214\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 827us/step - loss: 0.5729 - accuracy: 0.7070\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 851us/step - loss: 0.5660 - accuracy: 0.7096\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 852us/step - loss: 0.5658 - accuracy: 0.7227\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 839us/step - loss: 0.5809 - accuracy: 0.7135\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 912us/step - loss: 0.5584 - accuracy: 0.7305\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 847us/step - loss: 0.5627 - accuracy: 0.7148\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 854us/step - loss: 0.5607 - accuracy: 0.7214\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 849us/step - loss: 0.5584 - accuracy: 0.7201\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 889us/step - loss: 0.5551 - accuracy: 0.7240\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.5531 - accuracy: 0.7201\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.5540 - accuracy: 0.7135\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 826us/step - loss: 0.5534 - accuracy: 0.7201\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 836us/step - loss: 0.5590 - accuracy: 0.7240\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 856us/step - loss: 0.5874 - accuracy: 0.6927\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.5535 - accuracy: 0.7188\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 854us/step - loss: 0.5582 - accuracy: 0.7135\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 952us/step - loss: 0.5493 - accuracy: 0.7396\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 915us/step - loss: 0.5440 - accuracy: 0.7266\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 825us/step - loss: 0.5515 - accuracy: 0.7305\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7240\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 841us/step - loss: 0.5464 - accuracy: 0.7161\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 891us/step - loss: 0.5444 - accuracy: 0.7188\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 875us/step - loss: 0.5488 - accuracy: 0.7331\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 873us/step - loss: 0.5403 - accuracy: 0.7266\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 976us/step - loss: 0.5429 - accuracy: 0.7396\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 946us/step - loss: 0.5370 - accuracy: 0.7396\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 863us/step - loss: 0.5395 - accuracy: 0.7214\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 903us/step - loss: 0.5487 - accuracy: 0.7188\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 868us/step - loss: 0.5320 - accuracy: 0.7331\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 823us/step - loss: 0.5336 - accuracy: 0.7305\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 849us/step - loss: 0.5315 - accuracy: 0.7292\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 852us/step - loss: 0.5330 - accuracy: 0.7253\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.5259 - accuracy: 0.7409\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 861us/step - loss: 0.5466 - accuracy: 0.7188\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 803us/step - loss: 0.5318 - accuracy: 0.7474\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 947us/step - loss: 0.5405 - accuracy: 0.7396\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 865us/step - loss: 0.5308 - accuracy: 0.7409\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 869us/step - loss: 0.5319 - accuracy: 0.7318\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 920us/step - loss: 0.5332 - accuracy: 0.7383\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 870us/step - loss: 0.5252 - accuracy: 0.7422\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.5254 - accuracy: 0.7422\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 849us/step - loss: 0.5332 - accuracy: 0.7370\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 845us/step - loss: 0.5395 - accuracy: 0.7174\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 821us/step - loss: 0.5240 - accuracy: 0.7396\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 861us/step - loss: 0.5326 - accuracy: 0.7435\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 849us/step - loss: 0.5302 - accuracy: 0.7500\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 852us/step - loss: 0.5203 - accuracy: 0.7474\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 975us/step - loss: 0.5244 - accuracy: 0.7448\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 825us/step - loss: 0.5216 - accuracy: 0.7383\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 898us/step - loss: 0.5152 - accuracy: 0.7435\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 872us/step - loss: 0.5150 - accuracy: 0.7435\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 875us/step - loss: 0.5210 - accuracy: 0.7422\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 955us/step - loss: 0.5410 - accuracy: 0.7266\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 863us/step - loss: 0.5190 - accuracy: 0.7513\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 863us/step - loss: 0.5247 - accuracy: 0.7513\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 947us/step - loss: 0.5205 - accuracy: 0.7461\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 996us/step - loss: 0.5133 - accuracy: 0.7591\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 981us/step - loss: 0.5291 - accuracy: 0.7474\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 996us/step - loss: 0.5138 - accuracy: 0.7500\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 876us/step - loss: 0.5155 - accuracy: 0.7344\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 920us/step - loss: 0.5123 - accuracy: 0.7409\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 817us/step - loss: 0.5102 - accuracy: 0.7500\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 899us/step - loss: 0.5225 - accuracy: 0.7370\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.5111 - accuracy: 0.7461\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 830us/step - loss: 0.5154 - accuracy: 0.7383\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 938us/step - loss: 0.5079 - accuracy: 0.7617\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 853us/step - loss: 0.5173 - accuracy: 0.7383\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 871us/step - loss: 0.5094 - accuracy: 0.7500\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 914us/step - loss: 0.5068 - accuracy: 0.7617\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 849us/step - loss: 0.5059 - accuracy: 0.7552\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7422\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 973us/step - loss: 0.5094 - accuracy: 0.7487\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 891us/step - loss: 0.5086 - accuracy: 0.7513\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 828us/step - loss: 0.4965 - accuracy: 0.7513\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 844us/step - loss: 0.5078 - accuracy: 0.7409\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 839us/step - loss: 0.5106 - accuracy: 0.7500\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 877us/step - loss: 0.5052 - accuracy: 0.7461\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 939us/step - loss: 0.5003 - accuracy: 0.7591\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 864us/step - loss: 0.4966 - accuracy: 0.7565\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 963us/step - loss: 0.5034 - accuracy: 0.7500\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 995us/step - loss: 0.5001 - accuracy: 0.7656\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 986us/step - loss: 0.4999 - accuracy: 0.7500\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 988us/step - loss: 0.5016 - accuracy: 0.7487\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7643\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 981us/step - loss: 0.5045 - accuracy: 0.7513\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7617\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 867us/step - loss: 0.4954 - accuracy: 0.7682\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 983us/step - loss: 0.5036 - accuracy: 0.7500\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 877us/step - loss: 0.4955 - accuracy: 0.7526\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 850us/step - loss: 0.5035 - accuracy: 0.7487\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 841us/step - loss: 0.5028 - accuracy: 0.7565\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 841us/step - loss: 0.4974 - accuracy: 0.7643\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 948us/step - loss: 0.4964 - accuracy: 0.7617\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 878us/step - loss: 0.4953 - accuracy: 0.7526\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 887us/step - loss: 0.4909 - accuracy: 0.7656\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 861us/step - loss: 0.5052 - accuracy: 0.7526\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 837us/step - loss: 0.4859 - accuracy: 0.7643\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 855us/step - loss: 0.4925 - accuracy: 0.7643\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 894us/step - loss: 0.4894 - accuracy: 0.7539\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 847us/step - loss: 0.4900 - accuracy: 0.7656\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 860us/step - loss: 0.4920 - accuracy: 0.7630\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 847us/step - loss: 0.4854 - accuracy: 0.7656\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 840us/step - loss: 0.5025 - accuracy: 0.7487\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 901us/step - loss: 0.4923 - accuracy: 0.7630\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 922us/step - loss: 0.4908 - accuracy: 0.7617\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 994us/step - loss: 0.5007 - accuracy: 0.7526\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7604\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.7578\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 986us/step - loss: 0.4869 - accuracy: 0.7630\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 985us/step - loss: 0.4827 - accuracy: 0.7786\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 971us/step - loss: 0.4947 - accuracy: 0.7539\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7630\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 939us/step - loss: 0.4913 - accuracy: 0.7461\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 947us/step - loss: 0.4885 - accuracy: 0.7526\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 843us/step - loss: 0.4884 - accuracy: 0.7617\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 923us/step - loss: 0.4944 - accuracy: 0.7370\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 921us/step - loss: 0.4884 - accuracy: 0.7695\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 851us/step - loss: 0.4866 - accuracy: 0.7617\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 857us/step - loss: 0.4854 - accuracy: 0.7617\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 923us/step - loss: 0.4935 - accuracy: 0.7630\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 893us/step - loss: 0.4998 - accuracy: 0.7604\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 871us/step - loss: 0.4864 - accuracy: 0.7643\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 882us/step - loss: 0.4820 - accuracy: 0.7708\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 874us/step - loss: 0.4802 - accuracy: 0.7695\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 925us/step - loss: 0.4828 - accuracy: 0.7682\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 830us/step - loss: 0.4935 - accuracy: 0.7565\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 857us/step - loss: 0.4823 - accuracy: 0.7578\n",
            "24/24 [==============================] - 0s 906us/step - loss: 0.4724 - accuracy: 0.7708\n",
            "Loss: 0.47, Accuracy: 0.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hrl_TNqqmUG",
        "colab_type": "text"
      },
      "source": [
        "## Note, if you try running this example in an IPython or Jupyter notebook you may get an error.\n",
        "\n",
        "The reason is the output progress bars during training. You can easily turn these off by setting verbose=0 in the call to the fit() and evaluate() functions, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iNTcpG8plqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit the keras model on the dataset without progress bars\n",
        "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
        "# evaluate the keras model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBYIvUAmq3Ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2813de7-62b9-404a-e609-14abca3895db"
      },
      "source": [
        "print('Loss: {:.2f}'.format(loss) +', Accuracy: {:.2f}'.format(accuracy))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.44, Accuracy: 0.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlsDyqejrX_m",
        "colab_type": "text"
      },
      "source": [
        "##### Neural networks are a stochastic algorithm, meaning that the same algorithm on the same data can train a different model with different skill each time the code is run. This is a feature, not a bug. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-NO_SN7sZ6u",
        "colab_type": "text"
      },
      "source": [
        "#Â Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rH6rHD2q7O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make probability predictions with the model\n",
        "predictions = model.predict(X)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRoG7fW3sxpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "921b5f99-22a1-46ea-fcf8-f63b4fa2bcac"
      },
      "source": [
        "# make class predictions with the model\n",
        "predictions = model.predict_classes(X)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-e5fbfa914ea8>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPIkaz95xulf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = (model.predict(X) > 0.5).astype(\"int32\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlg5L_LMyDk4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bb96e60a-2eef-444d-e583-b211bde07536"
      },
      "source": [
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qH5tJE4yPR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}